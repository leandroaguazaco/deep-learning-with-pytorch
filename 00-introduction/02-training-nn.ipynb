{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2692f3c5",
   "metadata": {},
   "source": [
    "# [Training a Neural Network with PyTorch](https://campus.datacamp.com/courses/introduction-to-deep-learning-with-pytorch/training-a-neural-network-with-pytorch?ex=1)\n",
    "\n",
    "Third chapter in the Introduction to Deep Learning with PyTorch DataCamp course."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05716dd4",
   "metadata": {},
   "source": [
    "## 1 - A Deeper Dive Into Loading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c7e65a",
   "metadata": {},
   "source": [
    "Use  `TensorDataset` to prepare data for PyTorch models, storign features (X) and labels (y) as tensors, making them esay to manage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464aac87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.5  3.4  6.7]\n",
      " [ 1.2  5.   7.3]\n",
      " [34.2 44.  12.3]\n",
      " [ 0.4  6.7  2.2]] \n",
      "\n",
      "[0 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset\n",
    "import numpy as np\n",
    "\n",
    "# Features: 4 x 3 matrix\n",
    "# Four individuals, and 3 features\n",
    "inputs = np.array([\n",
    "    [0.5, 3.4, 6.7],\n",
    "    [1.2, 5.0, 7.3],\n",
    "    [34.2, 44.0, 12.3],\n",
    "    [0.4, 6.7, 2.2]\n",
    "])\n",
    "print(inputs, '\\n')\n",
    "\n",
    "# Labels: 4 x 1 matrix\n",
    "# 0 = specie one\n",
    "# 1 = specie two\n",
    "labels = np.array([\n",
    "    0, 0, 1, 0\n",
    "])\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "28f68bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Input sample: tensor([0.5000, 3.4000, 6.7000], dtype=torch.float64) \n",
      "\n",
      "    Label sample: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Instantiate dataset class\n",
    "dataset = TensorDataset(\n",
    "    torch.tensor(inputs),\n",
    "    torch.tensor(labels)\n",
    ")\n",
    "\n",
    "# Access an individual sample: square bracket indexing:\n",
    "input_sample, label_sample = dataset[0]\n",
    "print(f\"\"\"\n",
    "    Input sample: {input_sample} \\n\n",
    "    Label sample: {label_sample}\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b43673",
   "metadata": {},
   "source": [
    "* After to create the dataset using `TensorDataset` function, use the `DataLoader` function to manage data loading during training.\n",
    "\n",
    "* Since deep learning models require large datasets, batching helps process multiple samples at once, making training more efficient.\n",
    "\n",
    "* Shuffle randomizes the data order at each epoch, hepling improve model generalization.\n",
    "\n",
    "* **Epoch**: one full pass through the traning dataloader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "159ee46b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch inputs: \n",
      " tensor([[34.2000, 44.0000, 12.3000],\n",
      "        [ 0.5000,  3.4000,  6.7000]], dtype=torch.float64)\n",
      "Batch labels: \n",
      " tensor([1, 0]) \n",
      "\n",
      "Batch inputs: \n",
      " tensor([[1.2000, 5.0000, 7.3000],\n",
      "        [0.4000, 6.7000, 2.2000]], dtype=torch.float64)\n",
      "Batch labels: \n",
      " tensor([0, 0]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Define batch size\n",
    "# Determines how many samples are included in each iteration.\n",
    "batch_size = 2\n",
    "\n",
    "# Define shuffle:\n",
    "# Randomize the data order at each epoch\n",
    "shuffle = True\n",
    "\n",
    "# Create a DataLoader:\n",
    "# Easy to iterate through the dataset in batches\n",
    "dataloader = DataLoader(\n",
    "    dataset=dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Iterate over the dataloader\n",
    "for batch_inputs, batch_labels in dataloader:\n",
    "    print('Batch inputs: \\n', batch_inputs)\n",
    "    print('Batch labels: \\n', batch_labels, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda2ca3d",
   "metadata": {},
   "source": [
    "* In real world deep learning, datasets are much larger, with batch sizes of typically 32 or more for better computational efficiency.\n",
    "\n",
    "* The `DataLoader` class is essential for efficiently handling large datasets. It speeds up training, optimizes memory usage and stabilizes gradient updates, making deep learnig models more effective."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85ac4ae",
   "metadata": {},
   "source": [
    "## 2 - Writing a First Training Loop "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b54b8a",
   "metadata": {},
   "source": [
    "Training a neural network requires:\n",
    "- 1. Create a model\n",
    "- 2. Choose a loss function\n",
    "- 3. Define a dataset\n",
    "- 4. Set an optimizer\n",
    "- 5. Run a training loop\n",
    "    - 5.1. Calculate loss (forward pass)\n",
    "    - 5.2. Compute gradients (backpropagation)\n",
    "    - 5.3. Update model parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b54727",
   "metadata": {},
   "source": [
    "### 2.1 - Binary Classification Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fe36b606",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.optim as optim\n",
    "\n",
    "# 1) Create a model\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(3, 5),\n",
    "    nn.Linear(5, 5),\n",
    "    nn.Linear(5, 2)\n",
    ")\n",
    "\n",
    "# 2) Choose a loss function\n",
    "criterion = CrossEntropyLoss()\n",
    "\n",
    "# 3) Define a dataset\n",
    "dataset = TensorDataset(\n",
    "    torch.tensor(inputs).float(),\n",
    "    torch.tensor(labels).long()\n",
    ")\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    dataset=dataset,\n",
    "    batch_size=2,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# 4) Set an optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77cc8b2",
   "metadata": {},
   "source": [
    "Looping through the entire dataset once is called an epoch and we train over multiple epoch (num_epochs parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0a58b75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) Training loop\n",
    "num_epochs = 5\n",
    "\n",
    "for epoch in range(num_epochs): # For each epoch, we loop throug the dataloader\n",
    "    \n",
    "    for data in dataloader: # Each iteration of the dataloader provides a batch of samples\n",
    "        \n",
    "        # Set the gradients to zero because the optimizer stores gradientes from previous steps by default\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Get feature an targe from the dataloader\n",
    "        feature, target = data\n",
    "\n",
    "        # Run a forward pass\n",
    "        pred = model(feature)\n",
    "\n",
    "        # Compute loss and gradients\n",
    "        loss = criterion(pred, target)\n",
    "        loss.backward()\n",
    "\n",
    "        # Update the parameters\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df829364",
   "metadata": {},
   "source": [
    "### 2.2 - Regression Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "8de8a526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.5600],\n",
      "        [16.6975]], grad_fn=<AddmmBackward0>) torch.Size([2, 1])\n",
      "tensor([1.3000, 3.4000]) torch.Size([2])\n",
      "tensor(88.4456, grad_fn=<MseLossBackward0>) \n",
      "\n",
      "tensor([[-1.5703],\n",
      "        [-2.6054]], grad_fn=<AddmmBackward0>) torch.Size([2, 1])\n",
      "tensor([2.2000, 4.5000]) torch.Size([2])\n",
      "tensor(32.3509, grad_fn=<MseLossBackward0>) \n",
      "\n",
      "tensor([[-1.4400],\n",
      "        [-1.9352]], grad_fn=<AddmmBackward0>) torch.Size([2, 1])\n",
      "tensor([1.3000, 4.5000]) torch.Size([2])\n",
      "tensor(24.4597, grad_fn=<MseLossBackward0>) \n",
      "\n",
      "tensor([[-13.8494],\n",
      "        [ -0.8286]], grad_fn=<AddmmBackward0>) torch.Size([2, 1])\n",
      "tensor([3.4000, 2.2000]) torch.Size([2])\n",
      "tensor(153.3571, grad_fn=<MseLossBackward0>) \n",
      "\n",
      "tensor([[1.5015],\n",
      "        [1.5108]], grad_fn=<AddmmBackward0>) torch.Size([2, 1])\n",
      "tensor([2.2000, 1.3000]) torch.Size([2])\n",
      "tensor(0.2662, grad_fn=<MseLossBackward0>) \n",
      "\n",
      "tensor([[1.7618],\n",
      "        [8.0952]], grad_fn=<AddmmBackward0>) torch.Size([2, 1])\n",
      "tensor([4.5000, 3.4000]) torch.Size([2])\n",
      "tensor(14.7713, grad_fn=<MseLossBackward0>) \n",
      "\n",
      "tensor([[1.1140],\n",
      "        [1.2028]], grad_fn=<AddmmBackward0>) torch.Size([2, 1])\n",
      "tensor([2.2000, 1.3000]) torch.Size([2])\n",
      "tensor(0.5944, grad_fn=<MseLossBackward0>) \n",
      "\n",
      "tensor([[1.3640],\n",
      "        [4.8680]], grad_fn=<AddmmBackward0>) torch.Size([2, 1])\n",
      "tensor([4.5000, 3.4000]) torch.Size([2])\n",
      "tensor(5.9947, grad_fn=<MseLossBackward0>) \n",
      "\n",
      "tensor([[1.2241],\n",
      "        [1.0779]], grad_fn=<AddmmBackward0>) torch.Size([2, 1])\n",
      "tensor([1.3000, 2.2000]) torch.Size([2])\n",
      "tensor(0.6324, grad_fn=<MseLossBackward0>) \n",
      "\n",
      "tensor([[1.3732],\n",
      "        [4.4489]], grad_fn=<AddmmBackward0>) torch.Size([2, 1])\n",
      "tensor([4.5000, 3.4000]) torch.Size([2])\n",
      "tensor(5.4384, grad_fn=<MseLossBackward0>) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "from torch.nn import MSELoss\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.optim as optim\n",
    "\n",
    "# Redefine labels\n",
    "reg_inputs = np.array([\n",
    "    [0.5, 3.4, 6.7],\n",
    "    [1.2, 5.0, 7.3],\n",
    "    [34.2, 44.0, 12.3],\n",
    "    [0.4, 6.7, 2.2]\n",
    "])\n",
    "\n",
    "reg_labels = np.array([1.3, 4.5, 3.4, 2.2])\n",
    "\n",
    "# 1) Create a model\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(3, 5),\n",
    "    nn.Linear(5, 1),\n",
    ")\n",
    "\n",
    "# 2) Choose a loss function\n",
    "criterion = MSELoss()\n",
    "\n",
    "# 3) Define a dataset\n",
    "dataset = TensorDataset(\n",
    "    torch.tensor(reg_inputs).float(),\n",
    "    torch.tensor(reg_labels).float()\n",
    ")\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    dataset=dataset,\n",
    "    batch_size=2,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# 4) Set an optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "# 5) Training loop\n",
    "num_epochs = 5\n",
    "\n",
    "for epoch in range(num_epochs): # For each epoch, we loop throug the dataloader\n",
    "    \n",
    "    for data in dataloader: # Each iteration of the dataloader provides a batch of samples\n",
    "        \n",
    "        # Set the gradients to zero because the optimizer stores gradientes from previous steps by default\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Get feature an targe from the dataloader\n",
    "        feature, target = data\n",
    "\n",
    "        # Run a forward pass\n",
    "        pred = model(feature)\n",
    "        print(pred, pred.shape)\n",
    "        print(target, target.shape)\n",
    "\n",
    "        # Compute loss and gradients\n",
    "        loss = criterion(pred, target.unsqueeze(1))\n",
    "        print(loss, '\\n')\n",
    "        loss.backward()\n",
    "\n",
    "        # Update the parameters\n",
    "        optimizer.step()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-learning-with-pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
